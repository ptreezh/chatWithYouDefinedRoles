{
  "provider": "ollama",
  "model": "llama3:latest",
  "baseUrl": "http://localhost:11434",
  "apiKey": null,
  "temperature": 0.7,
  "maxTokens": 2048,
  "description": "本地Ollama模型配置 - 无需API密钥"
}